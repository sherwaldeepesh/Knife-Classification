####################
#
# Example Job for HTCondor
#
####################

#---------------------------------------------
# Name your batch so it's easy to distinguish in the q.
JobBatchName = "mlknife-train-resnet"

# --------------------------------------------
# Executable
executable   =  scripts/train.sh

# ---------------------------------------------------
# Universe (vanilla, docker)
universe     = docker
# docker_image = smishra03/stylegan2
# docker_image = nvcr.io/nvidia/pytorch:22.05-py3


docker_image = pytorch/pytorch:latest

initialdir = /mnt/fast/nobackup/users/ds01502/MLKnifeProject/EEEM066_Knife_Classification_code


# -------------------------------------------------
# Event, out and error logs
log    = DockerLogs/c$(cluster).p$(process).log
output = DockerLogs/c$(cluster).p$(process).out
error  = DockerLogs/c$(cluster).p$(process).error

# -----------------------------------
# File Transfer, Input, Output
should_transfer_files = YES

# Mount the project spaces containing the Anaconda environments and the code
# Uncomment this environment line if you're not running on /mnt/fast
#environment = "mount=/mnt/fast/nobackup/users/ds01502/MajorProjectCustomizableConditioningGANS/GANSketching"

# -------------------------------------
# Requirements for the Job (see NvidiaDocker/Example09)
requirements = (CUDAGlobalMemoryMb > 4500) && (CUDAGlobalMemoryMb <  23000) && \
#              (HasStornext) && \
               (CUDACapability > 2.0) && (Machine == "aisurrey16.surrey.ac.uk" || Machine == "aisurrey10.surrey.ac.uk" || Machine == "aisurrey04.surrey.ac.uk" || Machine == "aisurrey02.surrey.ac.uk" || Machine == "aisurrey05.surrey.ac.uk" || Machine == "aisurrey07.surrey.ac.uk")

# --------------------------------------
# Resources
request_GPUs   = 1
# this needs to be specified for the AI@Surrey cluster if requesting a GPU
+GPUMem        = 11000
request_CPUs   = 8
request_memory = 32G

#This job will complete in less than 1 hour
+JobRunTime = 21

#This job can checkpoint
+CanCheckpoint = false

# To assign rank for taking machine
Rank =  ((machine == "aisurrey08.surrey.ac.uk")*3) + ((machine == "aisurrey10.surrey.ac.uk")*2) + (machine == "slot1_2@aisurrey4.surrey.ac.uk")

# ------------------------------------
# Request for guaruanteed run time. 0 means job is happy to checkpoint and move at any time.
# This lets Condor remove our job ASAP if a machine needs rebooting. Useful when we can checkpoint and restore
# Measured in seconds, so it can be changed to match the time it takes for an epoch to run
MaxJobRetirementTime = 0

# -----------------------------------
# Queue commands. We can use variables and flags to launch our command with multiple options (as you would from the command line)
arguments = 
#$(train.py) --name $(name) --size $(size) --batch 4 --dataroot_sketch ./data/sketch/by_author/face1 --dataroot_image ./data/celeb-A/img_align_celeba/img_align_celeba --l_image 0.7 --g_pretrained ./pretrained/stylegan2-ffhq/netG.pth --d_pretrained ./pretrained/stylegan2-ffhq/netD.pth --transform_fake down2,toSketch,up2,to3ch --transform_real down2,up2,to3ch --reduce_visuals --disable_eval --diffaug_policy translation --display_freq 10 --save_freq 10 --max_iter 30  

# NOTE: Variable names can't contain dashes!
#script = $ENV(PWD)/run_metrics.py
#ckpt_dir = $ENV(PWD)/models
#models_list = $ENV(PWD)/weights/eval_list
#output = $ENV(PWD)/metric_results.csv
#name = authorsketch_ffhq1_celebA_augment_30k_new_n
#size = 1024

#$(script) --ckpt-dir $(ckpt_dir) --batch-size $(batch_size) --epochs $(epochs) --lr $(lr) --resume-training



#batch_size = 32
#epochs = 10
#lr = 0.01

#python run_metrics.py --models_list weights/eval_list --output metric_results.csv


queue 1